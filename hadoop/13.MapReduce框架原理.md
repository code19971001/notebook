## MapReduce框架的原理

### 1 InputFormat数据输入

#### 1.1 切片与MapTask并行度决定机制

1 思考

​	MapTask的并行度决定Map阶段的任务处理并发度，进而影响到整个Job的处理速度。

​	如果：1G的数据，启动8个MapTask，可以提高集群的并发处理能力。那么1K的数据，也启动8个MapTask，会提高集群性能吗？MapTask并行任务是否越多越好呢？哪些因素影响了MapTask并行度？

2 MapTask并行度决定机制

- **数据块：**Block是HDFS物理上把数据分成一块一块。
- **数据切片：**数据切片只是在逻辑上对输入进行分片，并不会在磁盘上将其切分成片进行存储。

![image-20210101153731713](https://gitee.com/code1997/blog-image/raw/master/images/image-20210101153731713.png)

#### 1.2 JOb提交流程源码详解

1 Job提交流程：waitForCompletion()

```java
waitForCompletion()

submit();

// 1建立连接
	connect();	
		// 1）创建提交Job的代理
		new Cluster(getConfiguration());
			// （1）判断是本地yarn还是远程
			initialize(jobTrackAddr, conf); 

// 2 提交job
submitter.submitJobInternal(Job.this, cluster)
	// 1）创建给集群提交数据的Stag路径
	Path jobStagingArea = JobSubmissionFiles.getStagingDir(cluster, conf);

	// 2）获取jobid ，并创建Job路径
	JobID jobId = submitClient.getNewJobID();

	// 3）拷贝jar包到集群
copyAndConfigureFiles(job, submitJobDir);	
	rUploader.uploadFiles(job, jobSubmitDir);

// 4）计算切片，生成切片规划文件
writeSplits(job, submitJobDir);
		maps = writeNewSplits(job, jobSubmitDir);
		input.getSplits(job);

// 5）向Stag路径写XML配置文件
writeConf(conf, submitJobFile);
	conf.writeXml(out);

// 6）提交Job,返回提交状态
status = submitClient.submitJob(jobId, submitJobDir.toString(), job.getCredentials());

```

Job提交流程：

![image-20210101160108528](https://gitee.com/code1997/blog-image/raw/master/images/image-20210101160108528.png)

#### 1.3 FileInputFormat切片机制

FileInputFormat切片流程：

![image-20210101160751348](https://gitee.com/code1997/blog-image/raw/master/images/image-20210101160751348.png)

FileInputFormat切片机制：

![image-20210101160947939](https://gitee.com/code1997/blog-image/raw/master/images/image-20210101160947939.png)

FileInputFormat切片大小的参数配置：

![image-20210101161023321](https://gitee.com/code1997/blog-image/raw/master/images/image-20210101161023321.png)

#### 1.4 CombineTextInputFormat 切片机制

​	框架默认的 TextInputFormat 切片机制是对任务按文件规划切片，不管文件多小，都会是一个单独的切片，都会交给一个 MapTask，这样如果有大量小文件，就会产生大量的MapTask，处理效率极其低下。

##### 1.4.1 应用的场景：

​	CombineTextInputFormat 用于小文件过多的场景，它可以将多个小文件从逻辑上规划到一个切片中，这样，多个小文件就可以交给一个 MapTask 处理。

##### 1.4.2 虚拟存储切片最大值设置：

```java
CombineTextInputFormat.setMaxInputSplitSize(job, 4194304);// 4m
```

##### 1.4.3 切片机制：

生成切片过程包括：虚拟存储过程和切片过程两部分：

![image-20210101164547663](https://gitee.com/code1997/blog-image/raw/master/images/image-20210101164547663.png)

1）虚拟存储过程：

将输入目录下所有文件大小，依次和设置的setMaxInputSplitSize值比较，如果不大于设置的最大值，逻辑上划分一个块。如果输入文件大于设置的最大值且大于两倍，那么以最大值切割一块；当剩余数据大小超过设置的最大值且不大于最大值2倍，此时将文件均分成2个虚拟存储块（防止出现太小切片）。

例如setMaxInputSplitSize值为4M，输入文件大小为8.02M，则先逻辑上分成一个4M。剩余的大小为4.02M，如果按照4M逻辑划分，就会出现0.02M的小的虚拟存储文件，所以将剩余的4.02M文件切分成（2.01M和2.01M）两个文件。

2）切片过程：

1. 判断虚拟存储的文件大小是否大于setMaxInputSplitSize值，大于等于则单独形成一个切片。
2. 如果不大于则跟下一个虚拟存储文件进行合并，共同形成一个切片。
3. 测试举例：有4个小文件大小分别为1.7M、5.1M、3.4M以及6.8M这四个小文件，则虚拟存储之后形成6个文件块，大小分别为：
4. 1.7M，（2.55M、2.55M），3.4M以及（3.4M、3.4M）

3）最终会形成3个切片，大小分别为：

（1.7+2.55）M，（2.55+3.4）M，（3.4+3.4）M

##### 1.4.4 实际操作

1）需求：

​	将输入的大量小文件合并成一个切片统一处理。

2）输入数据：

​	4个小文件

3）期望：

​	一个小切片处理4个文件。

4）案例分析：依旧使用之前的wordCount来进行处理。

```java
package com.it.wordcount;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

import java.io.IOException;

/**
 * @author : code1997
 * @date :2020-12-2020/12/31 18:05
 */
public class WordCountDriver {

    public static void main(String[] args) throws IOException, ClassNotFoundException, InterruptedException {
        args=new String[]{"e:/word1.txt","e:/word2.txt","e:/word3.txt","e:/word4.txt","e:/output"};

        //1.获取配置信息以及封装任务
        Configuration conf = new Configuration();
        Job job = Job.getInstance(conf);
        //2.设置jar的加载路径
        job.setJarByClass(WordCountDriver.class);
        //3.设置map和reduce类
        job.setMapperClass(WordCountMapper.class);
        job.setReducerClass(WordCountReducer.class);
        //4.设置map的输出
        job.setMapOutputKeyClass(Text.class);
        job.setMapOutputValueClass(IntWritable.class);
        //5.设置最终输出的kv类型
        job.setOutputKeyClass(Text.class);
        job.setOutputValueClass(IntWritable.class);
        //6.设置输入和输出路径
        FileInputFormat.setInputPaths(job, new Path(args[0]),new Path(args[1]),
                new Path(args[2]),new Path(args[3]));
        FileOutputFormat.setOutputPath(job, new Path(args[4]));
        //7.提交
        boolean result = job.waitForCompletion(true);
        System.exit(result ? 0 : 1);
    }
}
```

默认情况下：使用TextInputFormat.class，切片数为4

![image-20210101170746356](https://gitee.com/code1997/blog-image/raw/master/images/image-20210101170746356.png)

添加如下代码：

```java
//6.设置输入和输出路径
job.setInputFormatClass(CombineTextInputFormat.class);
CombineTextInputFormat.setMaxInputSplitSize(job, 1024*1024*4);
```

切片数为1：

![image-20210101171629662](https://gitee.com/code1997/blog-image/raw/master/images/image-20210101171629662.png)

我的文件均很小，为50字节大小，所以切片为1。

修改最大切片大小为55字节：

切片数为2：

![image-20210101173244323](https://gitee.com/code1997/blog-image/raw/master/images/image-20210101173244323.png)

#### 1.5 FileInputFormat实现类

​	在运行MapReduce程序的时候，输入的文件格式包括：基于行的日志文件，二进制格式文件，数据库表等，那么针对于不同的数据类型，MapReduce是如何读取这些数据的？

常见接口实现类：

- TextInputFormat：每次一行，也是默认的
- KeyValueTextInputFormat
- NLineInputFormat：按行处理
- CombineTextInputFormat：
- 自定以InputFormat

### 2 MapReduce工作流程

#### 2.1 流程图解

![image-20210101175727007](https://gitee.com/code1997/blog-image/raw/master/images/image-20210101175727007.png)



![image-20210101175712200](https://gitee.com/code1997/blog-image/raw/master/images/image-20210101175712200.png)

#### 2.2 流程详解

​	上面的流程是整个MapReduce最全工作流程，但是Shuffle过程只是从第7步开始到第16步结束，具体Shuffle过程详解，如下：

1）MapTask收集我们的map()方法输出的kv对，放到内存缓冲区中

2）从内存缓冲区不断溢出本地磁盘文件，可能会溢出多个文件

3）多个溢出文件会被合并成大的溢出文件

4）在溢出过程及合并的过程中，都要调用Partitioner进行分区和针对key进行排序

5）ReduceTask根据自己的分区号，去各个MapTask机器上取相应的结果分区数据

6）ReduceTask会取到同一个分区的来自不同MapTask的结果文件，ReduceTask会将这些文件再进行合并（归并排序）

7）合并成大文件后，Shuffle的过程也就结束了，后面进入ReduceTask的逻辑运算过程（从文件中取出一个一个的键值对Group，调用用户自定义的reduce()方法）

注意：

- huffle中的缓冲区大小会影响到MapReduce程序的执行效率，原则上说，缓冲区越大，磁盘io的次数越少，执行速度就越快。
- 缓冲区的大小可以通过参数调整，参数：io.sort.mb默认100M。

```java
context.write(k, NullWritable.get());
output.write(key, value);
collector.collect(key, value,partitioner.getPartition(key, value, partitions));
	HashPartitioner();
collect()
	close()
	collect.flush()
sortAndSpill()
	sort()   QuickSort
mergeParts();
	 
collector.close();
```