

### 1 官方GREP案例

​	By default, Hadoop is configured to run in a non-distributed mode, as a single Java process. This is useful for debugging.

​	The following example copies the unpacked conf directory to use as input and then finds and displays every match of the given regular expression. Output is written to the given output directory.

```shell
#创建文件夹：存放源文件
mkdir input
#复制一部分文件为数据源
cp etc/hadoop/*.xml input
#执行hadoop-mapreduce-examples-2.7.2.jar grep来对数据源进行计算。统计dfs开头的单词
bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar grep input output 'dfs[a-z.]+'
#打印输出
cat output/*
```

![image-20201229182445779](https://gitee.com/code1997/blog-image/raw/master/images/image-20201229182445779.png)

问题1：如果输出目录已经存在，会抛出异常

![image-20201229182535165](https://gitee.com/code1997/blog-image/raw/master/images/image-20201229182535165.png)

解决方式：删除输出目录，重新跑

### 2 官方WordCount案例

> 统计单词的个数。

1 创建一个文件夹wcinput

```shell
mkdir wcinput
```

2 创建文件源文件并添加信息

```shell
#创建文件
touch word.txt

#添加文件内容
hadoop yarn
hadoop mapreduce
atguigu
atguigu
```

3 执行wordCoount程序

```shell
bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount wcinput/ wcoutput
```

4 查看结果

```shell
cat wcoutput/part-r-00000
```

![image-20201229183648138](https://gitee.com/code1997/blog-image/raw/master/images/image-20201229183648138.png)



