## 伪分布式模式

### 1 伪分布式配置

#### 1.1 配置集群

> 配置文件均在hadoop的安装目录的etc/hadoop下

1）配置：hadoop-env.sh

修改JAVA_HOME的路径

```sh
export JAVA_HOME=/opt/module/jdk1.8
```

2）修改配置：etc/hadoop/core-site.xml

```shell
vim etc/hadoop/core-site.xml
```

![image-20201229192011423](https://gitee.com/code1997/blog-image/raw/master/images/image-20201229192011423.png)

添加如下信息：

```xml
<configuration>
    <property>
        <name>fs.defaultFS</name>
        <!--这里需要自己进行修改-->
        <value>hdfs://hadoop01:9000</value>
    </property>
    <property>
        <name>hadoop.tmp.dir</name>
        <value>/opt/module/hadoop-2.7.2/data/tmp</value>
    </property>
</configuration>
```

3）修改配置信息(可改可不改)：etc/hadoop/hdfs-site.xml

```xml
<!-- 指定HDFS副本的数量：默认副本数为3 -->
<property>
	<name>dfs.replication</name>
	<value>3</value>
</property>
```

#### 1.2 启动集群

1）**格式化NameNode**(第一次启动时格式化)

```shell
bin/hdfs namenode -format
```

2）启动NameNode

```shell
sbin/hadoop-daemon.sh start namenode

#关闭
sbin/hadoop-daemon.sh stop namenode
```

![image-20201229195031446](https://gitee.com/code1997/blog-image/raw/master/images/image-20201229195031446.png)

3）启动DataNode

```shell
sbin/hadoop-daemon.sh start datanode

#关闭
sbin/hadoop-daemon.sh stop datanode
```

![image-20201229195050161](https://gitee.com/code1997/blog-image/raw/master/images/image-20201229195050161.png)

#### 1.3 查看集群

1）使用jps查看：该命令是JDK的命令。

![image-20201229195146710](https://gitee.com/code1997/blog-image/raw/master/images/image-20201229195146710.png)

问题1：jsp不生效

原因：全局变量hadoop java没生效。

解决方式：`source /etc/profile`文件。

问题2：jsp发现进程没有，但是重新启动集群，提示进行已经开启。

原因：在linux的跟目录下/tmp目录中存在启动的进程临时文件，将集群相关进程删除掉，再重新启动集群。

2）使用web端查看

访问：http://192.168.134.141:50070/dfshealth.html#tab-overview

问题1：如果连接不上，可能是防火墙没有关。

```shell
#查看防火墙状态
systemctl status firewalld.service
#关闭防火墙
systemctl stop firewalld.service
#禁止开机启动
systemctl disable firewalld.service
```

![image-20201229201213830](https://gitee.com/code1997/blog-image/raw/master/images/image-20201229201213830.png)

#### 1.4 启动HDFS

1）常见操作：

```shell
#在hdfs中创建目录
bin/hdfs dfs -mkdir -p /user/it/input
#查看目录
bin/hdfs dfs -ls /
```

![image-20201229202205971](https://gitee.com/code1997/blog-image/raw/master/images/image-20201229202205971.png)

```shell
#查看多级目录
bin/hdfs dfs -lsr /
#或者
bin/hdfs dfs -ls -R /
```

![image-20201229204932078](https://gitee.com/code1997/blog-image/raw/master/images/image-20201229204932078.png)

```shell
#将本地中的文件wcinput/word.txt上传到hdfs上的/user/it/input下
bin/hdfs dfs -put wcinput/word.txt /user/it/input
```

![image-20201229203720534](https://gitee.com/code1997/blog-image/raw/master/images/image-20201229203720534.png)

2）此时使用workcount来计算hdfs上的文件

```shell
bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /user/it/input/word.txt /user/it/output
```

![image-20201229204440625](https://gitee.com/code1997/blog-image/raw/master/images/image-20201229204440625.png)

3）查看结果

```shell
bin/hdfs dfs -cat /user/it/output/*
```

![image-20201229204736235](https://gitee.com/code1997/blog-image/raw/master/images/image-20201229204736235.png)

#### 1.5 格式化细节

1）先关掉进程

jsp查看namenode和datanode，关闭这两个进程。

2）删除data文件夹和logs文件夹

#### 1.6 查看日志

catlog下的日志即可。

#### 1.7 格式化namenode注意点

1）查看datanode和namenode版本号

![image-20201229210636844](https://gitee.com/code1997/blog-image/raw/master/images/image-20201229210636844.png)

![image-20201229210721851](https://gitee.com/code1997/blog-image/raw/master/images/image-20201229210721851.png)

我们可以发现两者的clusterID一致，两者会进行通信，如果我们频繁的格式化namenode，可能会导致两者的clusterID不一致，可能会出现两者只有一个可以启动。

![image-20201229211201271](https://gitee.com/code1997/blog-image/raw/master/images/image-20201229211201271.png)

### 2 启动YARN并运行MR程序

#### 2.1 yarn的配置

1）配置yarn-env.sh：配置java_home

![image-20201229211626995](https://gitee.com/code1997/blog-image/raw/master/images/image-20201229211626995.png)

2）配置yarn-site.xml

```xml
<!-- Reducer获取数据的方式 -->
<property>
	<name>yarn.nodemanager.aux-services</name>
	<value>mapreduce_shuffle</value>
</property>

<!-- 指定YARN的ResourceManager的地址 -->
<property>
	<name>yarn.resourcemanager.hostname</name>
	<value>hadoop01</value>
</property>

```

3）配置mapred-env.sh：配置java_home

![image-20201229212202990](https://gitee.com/code1997/blog-image/raw/master/images/image-20201229212202990.png)

4）配置mapred-site.xml

将`mapred-site.xml.template`改为`mapred-site.xml`。可以选择复制`cp mapred-site.xml.template mapred-site.xml`

```xml
<!-- 指定MR运行在YARN上 -->
<property>
	<name>mapreduce.framework.name</name>
	<value>yarn</value>
</property>
```

#### 2.2 启动yarn

1）启动NameNode和DataNode

2）启动ResourceManager

```shell
sbin/yarn-daemon.sh start resourcemanager
```

3）启动NodeManager

```shell
sbin/yarn-daemon.sh start nodemanager
```

![image-20201229213423240](https://gitee.com/code1997/blog-image/raw/master/images/image-20201229213423240.png)

3）查看当前的进程

![image-20201229214102812](https://gitee.com/code1997/blog-image/raw/master/images/image-20201229214102812.png)

注：如果出现错误就查看对应的日志文件，来解决。

4）web端口查看：mapreduce：端口号：8088

链接：http://hadoop01:8088/cluster

![image-20201229214337693](C:\Users\龍\AppData\Roaming\Typora\typora-user-images\image-20201229214337693.png)

#### 2.3 MR测试

1）删除掉之前MR产生的目录output

```shell
#删除掉之前的output
bin/hdfs dfs -rm -r /user/it/output
```

![image-20201229214946599](https://gitee.com/code1997/blog-image/raw/master/images/image-20201229214946599.png)

2）测试wordcount

```shell
bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /user/it/input/word.txt /user/it/output
```

![image-20201229220500895](https://gitee.com/code1997/blog-image/raw/master/images/image-20201229220500895.png)

### 3 配置历史服务器

> 我们发现有一个history栏，但是单击也不能访问，需要配置历史服务器。配置完成后不必重新启动集群。

1）配置mapred-site.xml

```xml
<!-- 历史服务器端地址 -->
<property>
	<name>mapreduce.jobhistory.address</name>
	<value>hadoop01:10020</value>
</property>
<!-- 历史服务器web端地址 -->
<property>
	<name>mapreduce.jobhistory.webapp.address</name>
	<value>hadoop01:19888</value>
</property>
```

2）启动历史服务器

```shell
sbin/mr-jobhistory-daemon.sh start historyserver
```

3）查看是否启动：jps

![image-20201229221624824](https://gitee.com/code1997/blog-image/raw/master/images/image-20201229221624824.png)

4）查看JobHistory

链接：http://hadoop01:19888/jobhistory

![image-20201229221749054](https://gitee.com/code1997/blog-image/raw/master/images/image-20201229221749054.png)

5）此时查看之前的任务的history也可以查看

### 4 配置日志聚集

>日志聚集概念：应用运行完成以后，将程序运行日志上传到HDFS系统上，可以方便的查看程序的运行详情，方便开发调试。
>
>如下图的log

![image-20201229222234568](https://gitee.com/code1997/blog-image/raw/master/images/image-20201229222234568.png)

注意：开启日志聚集的功能，需要重新启动：nodeManager，ResourceManager和HistoryManager。

1）关闭nodeManager，ResourceManager和HistoryManager。

![image-20201229222714185](https://gitee.com/code1997/blog-image/raw/master/images/image-20201229222714185.png)

2）配置yarn-site.xml

```xml
<!-- 日志聚集功能使能 -->
<property>
	<name>yarn.log-aggregation-enable</name>
	<value>true</value>
</property>

<!-- 日志保留时间设置7天 -->
<property>
	<name>yarn.log-aggregation.retain-seconds</name>
	<value>604800</value>
</property>

```

3）启动NodeManager 、ResourceManager和HistoryManager

```shell
sbin/yarn-daemon.sh start resourcemanager

sbin/yarn-daemon.sh start nodemanager

sbin/mr-jobhistory-daemon.sh start historyserver

jps查看
```

4）删除HDFS上已经存在的输出文件

```shell
bin/hdfs dfs -rm -r /user/it/output
```

5）执行WordCount程序

```shell
bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /user/it/input/word.txt /user/it/output
```

6）查看程序的日志信息

链接：http://hadoop01:8088/cluster

进入到history->logs

可以查看到程序运行的过程中的运行信息。

![image-20201229223818326](https://gitee.com/code1997/blog-image/raw/master/images/image-20201229223818326.png)

### 5 配置文件的说明

​	Hadoop配置文件分两类：默认配置文件和自定义配置文件，只有用户想修改某一默认配置值时，才需要修改自定义配置文件，更改相应属性值。

1）默认的配置文件

| 要获取的默认文件     | 文件存放在Hadoop的jar包中的位置                             |
| -------------------- | ----------------------------------------------------------- |
| [core-default.xml]   | hadoop-common-2.7.2.jar/  core-default.xml                  |
| [hdfs-default.xml]   | hadoop-hdfs-2.7.2.jar/  hdfs-default.xml                    |
| [yarn-default.xml]   | hadoop-yarn-common-2.7.2.jar/  yarn-default.xml             |
| [mapred-default.xml] | hadoop-mapreduce-client-core-2.7.2.jar/  mapred-default.xml |

2）自定义配置文件

​	**core-site.xml、hdfs-site.xml、yarn-site.xml、mapred-site.xml**四个配置文件存放在$HADOOP_HOME/etc/hadoop这个路径上，用户可以根据项目需求重新进行修改配置。