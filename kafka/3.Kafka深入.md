## Kafka的工作流程

### 1 Kafka的工作流程

![image-20210914211120170](https://gitee.com/code1997/blog-image/raw/master/bigdata/image-20210914211120170.png)

Kafka中消息是以topic级别来进行分类的，生产者和消费者都是面向topic的(分区leader)，topic是逻辑上的概念，而partition是物理上的概念，每一个topic-partition对应一个log文件夹，该 log 文件夹中存储的就是 producer 生产的数据。Producer 生产的数据会被不断追加到该log 文件末端(顺序读写)，且每条数据都有自己的 offset。消费者组中的每个消费者，都会实时记录自己消费到了哪个 offset，以便consumer出错恢复时，从上次的位置继续消费。

注意：对于Kafka同一个topic来说，每一个分区维护一个自己的一个offset，并不是全局有序。

![image-20210914213015415](https://gitee.com/code1997/blog-image/raw/master/bigdata/image-20210914213015415.png)

### 2 文件存储机制

> 推荐：[Kafka文件的存储机制 - xuebusi - 博客园 (cnblogs.com)](https://www.cnblogs.com/jun1019/p/6256514.html#:~:text=Kafka文件的存储机制,同一个topic下有多个不同的partition，每个partition为一个目录，partition命名的规则是topic的名称加上一个序号，序号从0开始。 每一个partition目录下的文件被平均切割成大小相等（默认一个文件是500兆，可以手动去设置）的数据文件，)

![image-20210914213325618](https://gitee.com/code1997/blog-image/raw/master/bigdata/image-20210914213325618.png)

生产者生产的消息会不断地追加到log文件末尾，为了防止log文件过大导致数据定位效率低下，Kafka采用分片和索引机制。将每个partition分为多个segment，每个Segment对应一个index和一个log文件，将这些文件定位于一个文件夹下，该文件夹的命名规则为：topic+分区序号，比如first存在两个分区，那么文件夹名字为：

![image-20210914213733250](https://gitee.com/code1997/blog-image/raw/master/bigdata/image-20210914213733250.png)

如果给定topic，partition，index文件和log文件，kafka如何在log文件中快速定位数据？

![image-20210914213948569](https://gitee.com/code1997/blog-image/raw/master/bigdata/image-20210914213948569.png)

假设我们寻找offset=3的消息

1. 因为index和log文件的名字是log文件开始位置的起始偏移量，使用二分查找法定位index文件。
2. index文件中的每一条消息的大小是一定的，因此查找某一行数据的时候，可以使用偏移量的方式来快速定位到我们需要的数据，offset=3，并且存储了offset为3的消息的大小为756。
3. 二分查找找到log文件，然后根据偏移量，大小，快速定位到我们需要的消息。

![image-20210914215722895](https://gitee.com/code1997/blog-image/raw/master/bigdata/image-20210914215722895.png)

```txt
上图的左半部分是索引文件，里面存储的是一对一对的key-value，其中key是消息在数据文件（对应的log文件）中的编号，比如“1,3,6,8……”，
分别表示在log文件中的第1条消息、第3条消息、第6条消息、第8条消息……，那么为什么在index文件中这些编号不是连续的呢？
这是因为index文件中并没有为数据文件中的每条消息都建立索引，而是采用了稀疏存储的方式，每隔一定字节的数据建立一条索引。
这样避免了索引文件占用过多的空间，从而可以将索引文件保留在内存中。
但缺点是没有建立索引的Message也不能一次定位到其在数据文件的位置，从而需要做一次顺序扫描，但是这次顺序扫描的范围就很小了。

其中以索引文件中元数据3,497为例，其中3代表在右边log数据文件中从上到下第3个消息(在全局partiton表示第368772个消息)，
其中497表示该消息的物理偏移地址（位置）为497
```

### 3 Kafka生产者

#### 3.1 分区策略

1）分区的原因

- 方便集群扩展，每个 Partition 可以通过调整以适应它所在的机器，而一个 topic又可以有多个 Partition 组成，因此整个集群就可以适应任意大小的数据了。
- 可以提高读写并发能力，以 Partition 为单位读写，粒度更小。

2）分区原则

producer发送的消息被封装为`ProducerRecord`对象

- 指明 partition 的情况下，直接将指明的值直接作为 partiton。
- 没有指明 partition 值但有 key 的情况下，将 key 的 hash 值与 topic 的 partition数进行取余得到 partition 值；
- 既没有 partition 值又没有 key 值的情况下，第一次调用时随机生成一个整数（后面每次调用在这个整数上自增），将这个值与 topic 可用的 partition 总数取余得到 partition值，也就是常说的 round-robin 算法。

#### 3.2 数据可靠性

Kafka采用ack机制，当topic收到producer的数据之后，需要向producer发送ack(acknowledgement)，如果prodcuer收到ack，就会进行下一轮的发送，否则重新发送数据。

![image-20210914220418075](https://gitee.com/code1997/blog-image/raw/master/bigdata/image-20210914220418075.png)

1）副本同步策略--何时发送ack

| 方案                         | 优点                                                     | 缺点                                                         |
| ---------------------------- | -------------------------------------------------------- | ------------------------------------------------------------ |
| 半数以上完成同步，就发送 ack | 延迟底                                                   | 选举leader的时候，当我们容忍n台节点故障的时候，需要2n+1个副本 |
| 全部完成同步，才发送ack      | 选举新的leader的时候，容忍n台节点故障的时候需要n+1个副本 | 延迟高                                                       |

Kafka选用了第二种方案：

- Kafka的每个分区存在大量的数据，方案一会造成大量数据的冗余。
- 网络延迟对Kafka的影响比较小。

2）ISR--优化副本同步策略

问题：如果某个follower挂掉了，迟迟不能同步，那么不就卡住了？？

Leader 维护了一个动态的 in-sync replica set (ISR)，意为和 leader 保持同步的follower集合。ISR中的follower完成数据同步之后，需要向leader返回ack，如果一个follower长时间没有向leader同步数据，那么就被踢出ISR，时间阈值由参数`replica.lag.time.max.ms=10000`设置，而leader挂掉之后，也是从ISR中选举新的leader。

注：早期版本是时间+条数差，后来为什么取消了条数差？

因为Kafka Prodcuer是以batch的方式来发送数据的，假设条数差为10，batch为12条，那么可能每一个批次都会导致大量的follower不满足条数差而被移除ISR，而满足时间差，因此又被加入到ISR，会频繁的移除和加入follower到ISR中，尽管他是存在在内存中，但是ISR也是存在在zookeeper中，频繁的操作zookeeper也是不太好的。

3）ack应答机制--针对于生产者(不丢失数据)

所以 Kafka 为用户提供了三种可靠性级别，用户根据对可靠性和延迟的要求进行权衡，选择以下的配置。

ack参数设置：

- 0：producer 不等待 broker 的 ack，这一操作提供了一个最低的延迟，broker 一接收到还没有写入磁盘就已经返回，当 broker 故障时有可能丢失数据。
- 1：producer 等待 broker 的 ack，partition 的 leader 落盘成功后返回 ack，如果在 follower 同步成功之前 leader 故障，那么将可能会丢失数据。
- -1：producer 等待 broker 的 ack，partition 的 leader 和 follower 全部落盘成功后才返回 ack。但是如果在 follower 同步完成后，broker发送ack 之前，leader 发生故障，那么会造成数据重复。极限情况下，如果ISR中只有leader，leader挂掉了，可能会出现数据丢失。

4）故障处理-副本数据一致性

只是保证副本之间数据一致性问题，不保证丢不丢数据以及重复问题，这里的leader和follower是ISR中的机器。

![image-20210914221911879](https://gitee.com/code1997/blog-image/raw/master/bigdata/image-20210914221911879.png)

LEO ：Log End offset，指的是每个副本最大的 offset。
HW ：High WaterMark，指的是消费者能见到的最大的 offset ，ISR 队列中最小的 LEO

- follower 故障

  follower 发生故障后会被临时踢出 ISR，待该 follower 恢复后，follower 会读取本地磁盘记录的上次的 HW，并将 log 文件高于 HW 的部分截取掉，从 HW 开始向 leader 进行同步。等该 follower 的 LEO 大于等于该 Partition 的 的 HW，即 follower 追上 leader 之后，就可以重新加入 ISR 了。

- leader 故障

  leader 发生故障之后，会从 ISR 中选出一个新的 leader，之后，为保证多个副本之间的数据一致性，其余的 follower 会先将各自的 log 文件高于 HW 的部分截掉，然后从新的 leader同步数据。

#### 3.3 Exactly Once 语义

精准一次性消费语义。

1）At Least Once 语义

将服务器的 ACK 级别设置为-1，可以保证 Producer 到 Server 之间不会丢失数据。

2）At Most Once 语义

将服务器 ACK 级别设置为 0，可以保证生产者每条消息只会被发送一次。

3）Exactly Once 语义

对于一些非常重要的信息，比如说交易数据，下游数据消费者要求数据既不重复也不丢失。

对于0.11以下，无能为力，对于0.11及以上版本，Kafka引入了幂等性，幂等性+At least Once语义，就构成了Kafka的Exactly Once语义。

启动幂等性：Producer 的参数中 `enable.idompotence=true` 。

原理：开启幂等性的 Producer 在
初始化的时候会被分配一个 PID，发往同一 Partition 的消息会附带 Sequence Number。而Broker 端会对<PID, Partition, SeqNumber>做缓存，当具有相同主键的消息提交时，Broker 只会持久化一条。
缺点：无法保证跨分区会话的Exactly Once。

Kafka的 PID 重启就会变化，同时不同的 Partition 也具有不同主键，所以幂等性无法保证跨分区跨会话的 Exactly Once。

### 4 Kafka消费者

#### 4.1 消费方式

- 消费者主动pull：consumer 采用 pull（拉）模式从 broker 中读取数据，消费速率是根据消费者的消费能力来决定，但是需要维持一个长轮询，有可能一直返回空数据，针对这里，Kafka消费者在消费数据的时候会传入一个时长参数timeout，如果当时没有数据可用来消费，consumer会等待一段timeout时间再返回，用来减少长轮询的频率。(kafka使用)
- topic push：push （推）模式很难适应消费速率不同的消费者，因为消息发送速率是由 broker 决定的，因此如果消费者处理消息不及时，可能会造成消息的堆积。

#### 4.2 分区分配策略

一个 consumer group 中有多个 consumer，一个 topic 有多个 partition，所以必然会涉及到 partition 的分配问题，即确定那个 partition 由哪个 consumer 来消费。同一个消费者组的消费者不能同时消费同一个分区。

触发时机：消费者组的消费者个数发生变化的时候就会触发分区的重新分配。

1）RoundRobin--非默认的策略

会根据不同的topic的partition当作一个整体，进行一个排序，然后计算hash值开始轮询分配消费者，所以消费者组消费的partition的数目的差值最大为1。

问题：如果c1消费t1，c2消费t2，c1和c2是同一个消费者组，那么当成一个整体，可能会出现问题。c1消费t2，c2消费c1。

2）Range--默认策略

优先看谁订阅了topic，然后再看消费者组。一句topic对每一个消费者组进行划分。比如t1有7个分区，消费者组中存在3个消费者，那么0-2给c1，3-4给c2，5-6给c3。然后进行下一个topic的划分。

问题：如果topic的partition的数不是消费者组的消费者数的整数倍，那么会造成随着topic的增多，消费者之间压力失衡。

#### 4.3 offset的维护

由于 consumer 在消费过程中可能会出现断电宕机等故障，consumer 恢复后，需要从故障前的位置的继续消费，所以 consumer 需要实时记录自己消费到了哪个 offset，以便故障恢复后继续消费。topic+partition+消费者组唯一的确认一个offset。

![image-20210914235336588](https://gitee.com/code1997/blog-image/raw/master/bigdata/image-20210914235336588.png)

Kafka 0.9 版本之前，consumer 默认将 offset 保存在 Zookeeper 中，从 0.9 版本开始，consumer 默认将 offset 保存在 Kafka 一个内置的 topic 中，该 topic 为__consumer_offsets。

1）修改配置文件：允许我们消费kafka内部的topic。

consumer.properties

```properties
exclude.internal.topics=false
```

2）读取offset

consumer是相对topic `kafka-test`来说，相当于默认保存offset的topic `__consumer_offsets`来说，同时又是生产者。

```shell
bin/kafka-console-consumer.sh --topic __consumer_offsets --zookeeper hadoop02:2181 --formatter
"kafka.coordinator.GroupMetadataManager\$OffsetsMessageFormatter" --consumer.config config/consumer.properties --from-beginning

#0.11及之后
bin/kafka-console-consumer.sh --topic __consumer_offsets --zookeeper hadoop02:2181 --formatter "kafka.coordinator.group.GroupMetadataManager\$OffsetsMessageFormatter" --consumer.config config/consumer.properties --from-beginning
```

![image-20210915002505645](https://gitee.com/code1997/blog-image/raw/master/bigdata/image-20210915002505645.png)

消费者组+topic+分区：确定offset。

#### 4.4 消费者组案例

需求：同一个消费者组中的消费者，同一时刻只能有以一个消费者消费。

1）修改配置文件：`consumer.properties`

指定消费者组，否则每次启动就会给一个随机的消费者组。

```properties
group.id=kafka-test-group
```

2）在hadoop02和03上分别启动消费者

```shell
./kafka-console-consumer.sh --zookeeper hadoop02:2181 --topic kafka-test --consumer.config ../config/consumer.properties
```

3）在hadoop04上去启动生产者

4）观察同一时刻，只有一个消费者接收数据

### 5 Kafka高效读写

#### 5.1 顺序写

Kafka 的 producer 生产数据，要写入到 log 文件中，写的过程是一直追加到文件末端，为顺序写，省去了大量磁头寻址的时间，因此写的速度比较快。

#### 5.2 零复制

#### 5.3 零拷贝

推荐：[Kafka 中所谓的 ‘零拷贝’ 技术到底是什么？ - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/353182448#:~:text=Kafka 中所谓的 ‘零拷贝’ 技术到底是什么？ 除了消息 顺序追加、页缓存等技术 ，Kafka 还使用,语言，FileChannal.transferTo () 方法的底层实现就是 sendfile () 方法。 单纯从概念上理解“零拷贝”比较抽象，这里简单地介绍一下它。 考虑这样一种常用的情形：你需要将静态内容（类似图片、文件）展示给用户。)

![image-20210915005300361](https://gitee.com/code1997/blog-image/raw/master/bigdata/image-20210915005300361.png)

### 6 Zookeeper作用

Kafka 集群中有一个 broker 会被选举为 Controller，负责管理集群 broker 的上下线，所有 topic 的分区副本分配和 leader 选举等工作，controller的管理工作依赖于Zookeeper的，controller中的数据是共享的，但是还是需要选出一个controller来对zookeeper写数据。

争取机制：

![image-20210915005437044](https://gitee.com/code1997/blog-image/raw/master/bigdata/image-20210915005437044.png)

### 7 Kafka事务

Kafka事务+精准一次性语义=跨分区会话的精准一致性写数据到Kafka集群

#### 7.1 Producer事务

之前：如果我们producer发送给t1三个分区数据，分区1，2成功了，但是写分区3失败了，这个时候我们重启producer，然后会重发数据，分区1，2都会出现重复的现象。

为了实现跨分区跨会话的事务，需要引入一个全局唯一的 Transaction ID，并将 Producer获得的PID和Transaction ID绑定，这样当Producer重启后就可以通过正在进行的TransactionID 获得原来的 PID。

为了管理 Transaction，Kafka 引入了一个新的组件 Transaction Coordinator。Producer 就是通过和 Transaction Coordinator 交互获得 Transaction ID 对应的任务状态。TransactionCoordinator 还负责将事务所有写入 Kafka 的一个内部 Topic，这样即使整个服务重启，由于事务状态得到保存，进行中的事务状态可以得到恢复，从而继续进行。

#### 7.2 Consumer事务

对于 Consumer 而言，事务的保证就会相对较弱，尤其时无法保证 Commit 的信息被精确消费。这是由于 Consumer 可以通过 offset 访问任意信息，而且不同的 Segment File 生命周期不同，同一事务的消息可能会出现重启后被删除的情况。

