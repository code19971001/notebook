## Kafka Java API



#### 1.1 发送消息流程

Kafka 的 Producer 发送消息采用的是**异步发送**的方式。在消息发送的过程中，涉及到了两个线程——**main线程**和**Sender** **线程**，以及一个线程共享变量——**RecordAccumulator**。main 线程将消息发送给 RecordAccumulator，Sender 线程不断从 RecordAccumulator 中拉取消息发送到Kafka broker。

图解：

![image-20210915202653597](https://gitee.com/code1997/blog-image/raw/master/bigdata/image-20210915202653597.png)

相关参数：

- **batch.size**：只有数据积累到 batch.size 之后，sender 才会发送数据。
- **linger.ms：**如果数据迟迟未达到 batch.size，sender 等待 linger.time 之后就会发送数据。

依赖：

```xml
<dependency>
    <groupId>org.apache.kafka</groupId>
    <artifactId>kafka-clients</artifactId>
    <version>0.11.0.0</version>
</dependency>
```

#### 1.2 Producer api

相关类：

- KafkaProducer：需要创建一个生产者对象，用来发送数据
- ProducerConfig：获取所需的一系列配置参数
- ProducerRecord：每条数据都要封装成一个ProducerRecord 对象

```java
@Slf4j
public class MyProducer {

    KafkaProducer<String, String> producer;

    /**
     * 三个配置常量类：
     * CommonClientConfigs:公共的配置信息.
     * ProducerConfig:生产者的配置信息.
     * ConsumerConfig:消费者的配置信息.
     */
    @Before
    public void initProperty() {
        //1 创建kafka生产者的配置信息
        Properties properties = new Properties();
        //2 指定连接的kafka集群地址信息
        properties.put(CommonClientConfigs.BOOTSTRAP_SERVERS_CONFIG, "hadoop02:9092");
        //3 ack的应答级别
        properties.put(ProducerConfig.ACKS_CONFIG, "all");
        //4 重试次数
        properties.put(ProducerConfig.RETRIES_CONFIG, 3);
        //5 批次大小，单位是字节，字节16k
        properties.put(ProducerConfig.BATCH_SIZE_CONFIG, 16384);
        //6 等待时间
        properties.put(ProducerConfig.LINGER_MS_CONFIG, 1);
        //7 RecordAccumulator 缓冲区大小(32M)
        properties.put(ProducerConfig.BUFFER_MEMORY_CONFIG, 33554432);
        //8 k,v序列化方式
        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        producer = new KafkaProducer<>(properties);
    }

    /**
     * 注意发送数据是一批批的发送，因此可能不是很平均
     * 回调函数存在两个参数：metadata, exception
     * 注意ProducerRecord的参数
     */
    @Test
    public void sendByAsync() {
        for (int i = 0; i < 10; i++) {
            producer.send(new ProducerRecord<>("kafka-test", "code1997", "code1997" + i), (metadata, exception) -> {
                //回调函数
                if (exception == null) {
                    log.info("发送消息成功,topic:{},offset:{},partition:{}", metadata.offset(), metadata.offset(), metadata.partition());
                } else {
                    //说明发送消息失败
                    log.error("发送消息发生异常,topic:{},offset:{},partition:{}", metadata.offset(), metadata.offset(), metadata.partition(), exception);
                }
            });
        }
    }

    /**
     * 发送之后调用get方法会阻塞当前线程，相当于同步调用。
     * 生产环境中不怎么会用这种方式：因为效率比较低
     * 如果我们要保证全局有序的时候可能会用到：topic一个分区+同步调用。
     * 异步调用可能会乱序的原因：某一批消息发送失败，第二批发送，然后第一批重试。
     */
    @Test
    public void sendBySync() {
        for (int i = 0; i < 10; i++) {
            try {
                producer.send(new ProducerRecord<>("kafka-test", "code1997", "code1997" + i)).get();
            } catch (InterruptedException | ExecutionException e) {
                log.error("发送消息到kafka出现异常", e);
            }
        }
    }

    @After
    public void closeResource() {
        producer.close();
    }
}
```

#### 1.3 自定义分区器

分区策略：

- 如果指定分区，直接发送给指定的分区，就不走分区器。
- 如果存在key，对key求hashcode，然后对可用分区数求余。
- 如果key为null，使用round-robin算法。

```java
@Slf4j
public class MyPartitioner implements Partitioner {
    /**
     * 根据接受的参数，我们可以理解到，当到了分区器的时候，消息已经被序列化过了
     */
    @Override
    public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) {
        //获取当前topic的可用分区数
        int partitionCount = cluster.partitionCountForTopic(topic);
        log.info("topic:{},当前可用的分区数为:{}", topic, partitionCount);
        return 1;
    }

    @Override
    public void close() {

    }

    @Override
    public void configure(Map<String, ?> configs) {

    }
}
```

使用自定义分区器：

```java
@Slf4j
public class PartitionProducer {

    public static void main(String[] args) {
        //1 创建配置文件
        Properties properties = new Properties();
        //2 填写配置信息（链接，kv序列化）
        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "hadoop02:9092");
        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        //配置自定义的分区器
        properties.put(ProducerConfig.PARTITIONER_CLASS_CONFIG, MyPartitioner.class);
        KafkaProducer<String, String> producer = new KafkaProducer<>(properties);
        for (int i = 0; i < 10; i++) {
            producer.send(new ProducerRecord<>("kafka-test", "code1997", "code1997+++" + i),
                    ((metadata, exception) -> {
                        //回调函数
                        if (exception == null) {
                            log.info("发送消息成功,topic:{},offset:{},partition:{}", metadata.offset(), metadata.offset(), metadata.partition());
                        } else {
                            //说明发送消息失败
                            log.error("发送消息发生异常,topic:{},offset:{},partition:{}", metadata.offset(), metadata.offset(), metadata.partition(), exception);
                        }
                    }));
        }
        producer.close();
    }
}
```

源码：`DefaultPartitioner`

```java
public class DefaultPartitioner implements Partitioner {

    private final ConcurrentMap<String, AtomicInteger> topicCounterMap = new ConcurrentHashMap<>();

    public void configure(Map<String, ?> configs) {}

    /**
     * Compute the partition for the given record.
     *
     * @param topic The topic name
     * @param key The key to partition on (or null if no key)
     * @param keyBytes serialized key to partition on (or null if no key)
     * @param value The value to partition on or null
     * @param valueBytes serialized value to partition on or null
     * @param cluster The current cluster metadata
     */
    public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) {
        List<PartitionInfo> partitions = cluster.partitionsForTopic(topic);
        int numPartitions = partitions.size();
        if (keyBytes == null) {
            int nextValue = nextValue(topic);
            List<PartitionInfo> availablePartitions = cluster.availablePartitionsForTopic(topic);
            if (availablePartitions.size() > 0) {
                int part = Utils.toPositive(nextValue) % availablePartitions.size();
                return availablePartitions.get(part).partition();
            } else {
                // no partitions are available, give a non-available partition
                return Utils.toPositive(nextValue) % numPartitions;
            }
        } else {
            // hash the keyBytes to choose a partition
            return Utils.toPositive(Utils.murmur2(keyBytes)) % numPartitions;
        }
    }

    private int nextValue(String topic) {
        AtomicInteger counter = topicCounterMap.get(topic);
        if (null == counter) {
            counter = new AtomicInteger(ThreadLocalRandom.current().nextInt());
            AtomicInteger currentCounter = topicCounterMap.putIfAbsent(topic, counter);
            if (currentCounter != null) {
                counter = currentCounter;
            }
        }
        return counter.getAndIncrement();
    }

    public void close() {}

}
```

#### 1.4 Consumer Api

Consumer 消费数据时的可靠性是很容易保证的，因为数据在 Kafka 中是持久化的，故不用担心数据丢失问题。

由于 consumer 在消费过程中可能会出现断电宕机等故障，consumer 恢复后，需要从故障前的位置的继续消费，所以 consumer 需要实时记录自己消费到了哪个 offset，以便故障恢复后继续消费。

所以消费者主要考虑的是offset的维护。

涉及的类：

- KafkaConsumer：需要创建一个消费者对象，用来消费数据
- ConsumerConfig：获取所需的一系列配置参数
- ConsuemrRecord：每条数据都要封装成一个 ConsumerRecord 对象

涉及的参数：

- enable.auto.commit：是否开启自动提交 offset 功能
- auto.commit.interval.ms：自动提交 offset 的时间间隔

代码：

```shell
@Slf4j
public class MyConsumer {
    public static void main(String[] args) {
        //1 创建一个消费者的properties
        Properties properties = new Properties();
        //2 给消费信息赋值
        //2.1 连接的集群信息
        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, "hadoop02:9092");
        //2.2 自动提交的延时
        properties.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, "1000");
        //2.3 开启自动提交offset：存在bug，会丢失数据，例如数据还没有处理完，offset已经提交，此时挂掉了。
        //kafka默认存在两种提交方式，
        //1 自动提交：基于时间提交的，难以把控offset提交的时机，
        //2 手动提交：处理完数据然后进行提交，会出现重复数据。例如：当处理完成之后，将要提交的时候，挂掉了。
        // 同步提交：会阻塞线程，直到提交成功
        // 异步提交：kafka官方的发现存在bug，官方提供了自定义的方式。我们可以采取事务的方式进行提交。
        properties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, "true");
        //2.4 k,v反序列化
        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG,
                "org.apache.kafka.common.serialization.StringDeserializer");
        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG,
                "org.apache.kafka.common.serialization.StringDeserializer");
        //消费者组
        properties.put(ConsumerConfig.GROUP_ID_CONFIG, "code1997");
        //重置消费者的offset：可以拿到之前的数据：用来重新消费数据
        //两种情况下生效：
        //1 消费者组第一次消费
        //2 消费者挂掉了，等了7天，offset失效了。
        //默认属性为：latest
        properties.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest");
        //创建消费者
        KafkaConsumer<String, String> consumer = new KafkaConsumer<>(properties);
        //订阅主题:如果有个主题真的找不到也不会报错,只会存在一个警告.
        consumer.subscribe(Collections.singletonList("kafka-test"));
        flag:
        while (true) {
            //获取订阅主题的数据
            //添加拉取延迟时间，并拉取数据
            ConsumerRecords<String, String> records = consumer.poll(100);
            //解析并打印consumerRecords
            for (ConsumerRecord<String, String> consumerRecord : records) {
                log.info(consumerRecord.key() + "------" + consumerRecord.value());
            }
        }
    }
}
```

`auto.offset.reset`配置重置offset

- 配置生效的前提
  - 消费者组第一次消费
  - 消费者挂掉了，等了7天，offset失效了。

- 值选项
  - earliest：从最早的开始消费
  - latest：从最新开始消费

#### 1.5 手动提交offset

虽然自动提交 offset 十分简介便利，但由于其是基于时间提交的，开发人员难以把握offset 提交的时机。因此 Kafka 还提供了手动提交 offset 的 API，将本次poll的一批数据最高的偏移量提交。

内存和硬盘中都维护了一个各自的offset，当消费者启动的时候才会访问硬盘中的offset一次，如果我们没有自动提交，那么一直不会更新硬盘中的offset，如果此时消费者挂掉了，那么会出现重复消费的现象。

方式：

- commitSync：同步提交，会阻塞当前进程，直到提交成功，并且会自动失败重试。
- commitAsync：异步提交，没有重试机制，因此可能会提交失败。

```java
        KafkaConsumer<String, String> consumer = new KafkaConsumer<>(properties);
        //订阅主题:如果有个主题真的找不到也不会报错,只会存在一个警告.
        consumer.subscribe(Collections.singletonList("kafka-test"));
        flag:
        while (true) {
            //获取订阅主题的数据
            //添加拉取延迟时间，并拉取数据
            ConsumerRecords<String, String> records = consumer.poll(100);
            //解析并打印consumerRecords
            for (ConsumerRecord<String, String> consumerRecord : records) {
                log.info(consumerRecord.key() + "------" + consumerRecord.value());
            }
            //同步提交offset
            //consumer.commitSync();
            //异步提交offset
            consumer.commitAsync((offsets, exception) -> {
                if (exception==null){
                    log.info("commit successful for offsets:{}", offsets);
                }else {
                    log.info("commit failed for offsets:{}", offsets);
                }
            });
        }
```

数据漏消费和重复消费分析：

无论是同步提交还是异步提交 offset，都有可能会造成数据的漏消费或者重复消费。先提交 offset 后消费，有可能造成数据的漏消费；而先消费后提交 offset，有可能会造成数据的重复消费。



